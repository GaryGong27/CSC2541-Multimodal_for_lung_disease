{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import time\n",
    "####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "####\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "##\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from PIL import Image\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.join(os.path.dirname(os.getcwd()),\"data\")\n",
    "data_path = Path(data_directory)\n",
    "full_train_df = pd.read_csv(os.path.join(data_path, Path('archive/train.csv')))\n",
    "full_valid_df = pd.read_csv(os.path.join(data_path, Path('archive/valid.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_one_features = ['Atelectasis', 'Edema']\n",
    "u_zero_features = ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']\n",
    "\n",
    "full_train_df['Cardiomegaly'] = full_train_df['Cardiomegaly'].replace(-1,0)\n",
    "full_train_df['Consolidation'] = full_train_df['Consolidation'].replace(-1,0)\n",
    "full_train_df['Pleural Effusion'] = full_train_df['Pleural Effusion'].replace(-1,0)\n",
    "\n",
    "full_train_df['Atelectasis'] = full_train_df['Atelectasis'].replace(-1,1)\n",
    "full_train_df['Edema'] = full_train_df['Edema'].replace(-1,1)\n",
    "full_train_df = full_train_df.replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(full_train_df, test_size=0.20, random_state=2021)\n",
    "del full_train_df\n",
    "del full_valid_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes=14, is_trained=False):\n",
    "        super().__init__()\n",
    "        self.net = torchvision.models.densenet121(pretrained=is_trained)\n",
    "        out = self.net.classifier.in_features\n",
    "        self.net.classifier = nn.Sequential(nn.Linear(out,num_classes), nn.Sigmoid())\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=14,is_trained=False):\n",
    "        super.__init__()\n",
    "        self.net = torchvision.models.resnet50(pretrained=is_trained)\n",
    "\n",
    "        counter = 0\n",
    "        for child in self.net.children():\n",
    "            counter +=1\n",
    "            if counter <= 8:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "        self.net.fc = nn.Sequential(\n",
    "               nn.Linear(self.net.fc.in_features, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, num_classes),nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        return self.net(inputs)\n",
    "\n",
    "        #Replace last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, folder_dir, dataframe, image_size, normalization, data_limit=10000):\n",
    "\n",
    "        self.image_paths = [] # List of image paths\n",
    "        self.image_labels = [] # List of image labels\n",
    "        \n",
    "        # Define list of image transformations\n",
    "        image_transformation = [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "        \n",
    "        self.image_transformation = transforms.Compose(image_transformation)\n",
    "        \n",
    "        # Get all image paths and image labels from dataframe\n",
    "        for index, row in dataframe.iterrows():\n",
    "            path_parts = row.Path.split('/')\n",
    "            # Remove the first directory by slicing the list from the second element onwards\n",
    "            img_data_path = path_parts[1:]\n",
    "            img_data_path.insert(0,'archive')\n",
    "            new_path = '\\\\'.join(img_data_path)\n",
    "            image_path = os.path.join(folder_dir, new_path)\n",
    "            self.image_paths.append(image_path)\n",
    "            if len(row) < 14:\n",
    "                labels = [0] * 14\n",
    "            else:\n",
    "                labels = []\n",
    "                for col in row[5:]:\n",
    "                    if col == 1:\n",
    "                        labels.append(1)\n",
    "                    else:\n",
    "                        labels.append(0)\n",
    "            self.image_labels.append(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Read image at index and convert to torch Tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        # Read image\n",
    "        image_path = self.image_paths[index]\n",
    "        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n",
    "\n",
    "        image_data = self.image_transformation(image_data)\n",
    "        \n",
    "        return image_data, torch.FloatTensor(self.image_labels[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "BATCH_SIZE = 150                             \n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 30 ##100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = ChestXrayDataset(data_directory, train_data, IMAGE_SIZE, True)\n",
    "len(train_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only take 5% of data \n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "subset_size = 0.05  # 5% of the dataset\n",
    "num_samples = len(train_data_set)\n",
    "num_val_sample = len(val_data)\n",
    "subset_indices = torch.randperm(num_samples)[:int(subset_size * num_samples)]\n",
    "subset_indices_val = torch.randperm(num_val_sample)[:int(subset_size * num_val_sample)]\n",
    "subset_sampler = SubsetRandomSampler(subset_indices)\n",
    "subset_val_sampler = SubsetRandomSampler(subset_indices_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset=train_data_set, sampler= subset_sampler, batch_size=BATCH_SIZE, shuffle=False)\n",
    "device = get_default_device()\n",
    "train_data_loader = DeviceDataLoader(train_data_loader, device)\n",
    "\n",
    "\n",
    "val_dataset = ChestXrayDataset(data_directory, val_data, IMAGE_SIZE, True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, sampler=subset_val_sampler, batch_size=BATCH_SIZE, shuffle=False)\n",
    "device = get_default_device()\n",
    "val_dataloader = DeviceDataLoader(val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_auroc(y_gt, y_pred):\n",
    "    \"\"\" Calculate AUROC for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    auroc = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        try:\n",
    "            auroc.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return auroc\n",
    "\n",
    "def multi_label_accuracy(y_gt, y_pred):\n",
    "    \"\"\" Calculate AUROC for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        acc.append(accuracy_score(gt_np[:, i], np.where(pred_np[:, i]>=0.5,1,0)))\n",
    "    return acc\n",
    "\n",
    "def multi_label_f1(y_gt, y_pred):\n",
    "    \"\"\" Calculate f1 for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    f1_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        f1_out.append(f1_score(gt_np[:, i], np.where(pred_np[:, i]>=0.5,1,0)))\n",
    "    return f1_out\n",
    "\n",
    "\n",
    "def multi_label_precision_recall(y_gt, y_pred):\n",
    "    \"\"\" Calculate precision for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        precision of each class\n",
    "    \"\"\"\n",
    "    precision_out = []\n",
    "    recall_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        p = precision_recall_fscore_support(gt_np[:, i], np.where(pred_np[:, i]>=0.5,1,0),average='binary')\n",
    "        precision_out.append(p[0])\n",
    "        recall_out.append(p[1])\n",
    "    return precision_out,recall_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_training(epoch, model, train_data_loader, loss_criteria, optimizer, mb):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "\n",
    "    for batch, (image, label) in enumerate(progress_bar(train_data_loader,parent=mb)):\n",
    "\n",
    "        #Zero the previous grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Run forward pass\n",
    "        output = model(image)\n",
    "        \n",
    "        #Calculate the backward loss\n",
    "        loss = loss_criteria(output, label)\n",
    "\n",
    "        #Do GD\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # return training loss\n",
    "    return training_loss/len(train_data_loader)\n",
    "\n",
    "\n",
    "def evaluating(epoch, model, val_loader, loss_criteria, mb):\n",
    "    model.eval()\n",
    "    val_loss = 0                                   # Total loss of model on validation set\n",
    "    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    out_gt = torch.FloatTensor().to(device) \n",
    "    with torch.no_grad():\n",
    "         for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n",
    "             \n",
    "             out_gt = torch.cat((out_gt,labels),0)\n",
    "\n",
    "             ps = model(images)\n",
    "             loss = loss_criteria(ps, labels)\n",
    "             out_pred = torch.cat((out_pred, ps), 0)\n",
    "\n",
    "            # Update validation loss after each batch\n",
    "             val_loss += loss\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    val_loss_mean = val_loss/len(val_loader)\n",
    "    auroc_mean = np.nanmean(np.array(multi_label_auroc(out_gt, out_pred)))\n",
    "    acc_mean = np.nanmean(np.array(multi_label_accuracy(out_gt, out_pred)))\n",
    "    f1_mean = np.nanmean(np.array(multi_label_f1(out_gt, out_pred)))\n",
    "    \n",
    "    return val_loss_mean,auroc_mean,acc_mean,f1_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt(modeltxt,model):\n",
    "    \n",
    "    if modeltxt == \"DenseNet121\":\n",
    "        return optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "    if modeltxt == \"ResNet50\":\n",
    "        return optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list = [DenseNet121,ResNet50]\n",
    "mName_list = ['DenseNet121','ResNet50']\n",
    "out = data_directory = os.path.join(os.path.dirname(os.getcwd()),\"model\\\\image\")\n",
    "def actual_training(modelname,loss_criteria,modeltxt):\n",
    "    model = modelname(14, is_trained=True).to(device)\n",
    "\n",
    "    optimizer = get_opt(modeltxt, model)\n",
    "\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR,\n",
    "                                                        patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)\n",
    "    \n",
    "    model_path = out+modeltxt+\".pth\"\n",
    "\n",
    "    best_score = 0\n",
    "    best_score_acc = 0\n",
    "    best_score_f1 = 0\n",
    "    \n",
    "    out_path = out+modeltxt+\"_running.csv\"\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    validation_score = []\n",
    "    validation_acc = []\n",
    "    validation_f1 = []\n",
    "\n",
    "    mb = master_bar(range(MAX_EPOCHS))\n",
    "    mb.names = ['Train loss', 'Val loss', 'AUROC', 'Accuracy', 'f1 score']\n",
    "    x = []\n",
    "\n",
    "    nonimproved_epoch = 0\n",
    "    start_time = time.time()\n",
    "    cnt = 1\n",
    "\n",
    "    #training\n",
    "\n",
    "    for epoch in mb:\n",
    "        mb.main_bar.comment = f'Best AUROC score: {best_score}'\n",
    "        x.append(epoch)\n",
    "\n",
    "        train_loss = epoch_training(epoch, model, train_data_loader, loss_criteria, optimizer,mb)\n",
    "        mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n",
    "        training_losses.append(train_loss)\n",
    "\n",
    "        val_loss, new_score, new_score_acc, new_score_f1 = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n",
    "\n",
    "        validation_losses.append(val_loss)\n",
    "        validation_score.append(new_score)\n",
    "        validation_acc.append(new_score_acc)\n",
    "        validation_f1.append(new_score_f1)\n",
    "\n",
    "        gc.collect()\n",
    "        # Update learning rate\n",
    "        lr_scheduler.step(new_score)\n",
    "\n",
    "        mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score] , [x, validation_acc] ,\n",
    "                         [x, validation_f1]],\n",
    "                        [0,epoch+1+round(epoch*0.3)], [0,1])\n",
    "\n",
    "        diff = np.round(time.time() - start_time)\n",
    "\n",
    "        t2 = 4\n",
    "        if modeltxt == 'DenseNet121':\n",
    "            t2 = 6\n",
    "        if best_score < new_score:\n",
    "            #mb.write(f\"Improve AUROC from {best_score} to {new_score}\")    \n",
    "            best_score = new_score\n",
    "            best_score_acc = new_score_acc\n",
    "            best_score_f1 = new_score_f1\n",
    "            nonimproved_epoch = 0\n",
    "            best_model = model\n",
    "            torch.save({\"model\": model.state_dict(), \n",
    "                        \"optimizer\": optimizer.state_dict(), \n",
    "                        \"best_score\": best_score, \n",
    "                        \"epoch\": epoch, \n",
    "                        \"lr_scheduler\": lr_scheduler.state_dict()}, model_path)\n",
    "        else: \n",
    "            nonimproved_epoch += 1\n",
    "        if nonimproved_epoch > 5:\n",
    "            break\n",
    "            print(\"Early stopping\")\n",
    "        if time.time() - start_time > 3600*t2:\n",
    "            break\n",
    "            print(\"Out of time\")\n",
    "        return best_score,best_score_acc,best_score_f1,best_model\n",
    "\n",
    "eval_df_train = []\n",
    "for m in model_list:\n",
    "    mName = m().__class__.__name__\n",
    "    print(\"Processing Model \",mName)\n",
    "    globals()[f\"best_score_{mName}\"],globals()[f\"best_score_acc_{mName}\"],globals()[f\"best_score_f1_{mName}\"], \\\n",
    "        globals()[f\"best_model_{mName}\"] = actual_training(modelname=m,loss_criteria=nn.BCELoss(),modeltxt=mName)\n",
    "    eval_df_train.append([mName,globals()[f\"best_score_{mName}\"],globals()[f\"best_score_acc_{mName}\"],globals()[f\"best_score_f1_{mName}\"]])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
